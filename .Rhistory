count() %>%
print() # n = 2 dupes (jUly 2023)
# Show duplicate:
results_exercise2 %>%
group_by(Title) %>%
filter(n()>1) %>%
# View()
print() # These all have different PMIDs, DOIs, authors, and years
# Have a look at duplicates where the title, year, and authors are all the same:
results_exercise2 %>%
group_by(Title,
Journal_name_short,
Full_Author_Name) %>%
filter(n()>1)
# print() #None
# Have a look at duplicates were just the title, journal and year are the same:
results_exercise2 %>%
group_by(Title,
Journal_name_short,
Year) %>%
filter(n()>1) %>%
print() # None
#  Okay, now we're confident we have a clean dataset, let's explore!
# Summary of the Year  variable:
summary(results_exercise2$Year)
# Number of publications per year:
exercise_hist<- hist(results_exercise2$Year,
xlim = c(1960,2023),
breaks = 40,
main = "Papers published per year on exercise Disorder (PubMed)",
xlab = "Year")
# Number of separate journals:
results_exercise2 %>%
distinct(Journal_name_short) %>%
arrange(Journal_name_short) %>%
print(n = 20)
# Most popular journals:
results_exercise2 %>%
group_by(Journal_name_short) %>%
summarise(
n = n()
) %>%
arrange(desc(n)) %>%
print(n = 20)
# View(results_exercise2) # Visually inspect results
# Now I need to add a label to all of these studies to signify that they Were returned from the exercise search so that we can distinguish them from other studies when we later joined the datasets together:
Label <- rep("exercise", times = count(results_exercise2))
results_exercise_final <- results_exercise2 %>% bind_cols(Label) %>%
rename(Label = 14) %>%
print()
# View(results_exercise_final)
# Now save the cleaned results
write.csv(results_exercise_final, "Data extraction/exercise_data_cleaned.csv", row.names=FALSE)
# Add search URL:
url_exercise_rvest <- "https://pubmed.ncbi.nlm.nih.gov/?term=%28%28%28%28%22Exercise+addiction%22%5BTitle%2FAbstract%5D%29+OR+%28%22exercise+dependence%22%5BTitle%2FAbstract%5D%29%29+OR+%28%22compulsory+exercise%22%5BTitle%2FAbstract%5D%29%29+OR+%28%22obligatory+exercise%22%5BTitle%2FAbstract%5D%29%29+OR+%28%22Addiction+to+exercise%22%5BTitle%2FAbstract%5D%29&size=200" # 386 results returned on 10/07/2023
# Read and parse the webpage
webpage_exercise_rvest <- read_html(url_exercise_rvest)
# Get the total number of search results
results_count_exercise <- webpage_exercise_rvest %>%
html_node(".results-amount .value") %>%
html_text() %>%
str_replace(",", "") %>%
as.numeric()
# Calculate the number of pages
results_per_page_exercise <- 50
total_pages_exercise <- ceiling(results_count_exercise[1] / results_per_page_exercise)
# Print results_count_exercise and total_pages_exercise
print(results_count_exercise)
print(total_pages_exercise)
# Initialize an empty data frame
results_exercise_rvest <- data.frame()
# Loop through each page and scrape the data
for (page in 0:(total_pages_exercise - 1)) {
# Update the page parameter in the URL for the current page
current_url <- paste0(url_exercise_rvest, "&page=", page + 1)
# Read and parse the current webpage
current_page <- read_html(current_url)
# Extract title
Title <- tryCatch({
current_page %>%
html_nodes(".docsum-title") %>%
html_text(trim = TRUE)
}, error = function(e) {
print(paste("Error extracting title info on page", page + 1))
rep(NA, length(Title))  # Return a vector of NAs with the same length as Title
})
# Extract the PMID
pmid <- current_page %>%
html_nodes(".docsum-pmid") %>%
html_text(trim = TRUE)
# Create a data frame with the extracted data
current_results_exercise <- data.frame(Title = Title,
PMID = pmid)
# Combine the current results with the previous results
results_exercise_rvest <- rbind(results_exercise_rvest, current_results_exercise)
# Introduce a delay to avoid overloading the server
sleep_time <- runif(1, min = 5, max = 15)
Sys.sleep(sleep_time)
}
# Print the extracted data
print(as_tibble(results_exercise_rvest))
# Now save the titles before proceeding so we can't lose them!
write.csv(results_exercise_rvest, "Data extraction/exercise_titles.csv", row.names=FALSE)
# Load in first dataset in case environment clean on knit (above sections not executed for render):
results_work<- read.csv("Data extraction/work_data.csv") %>%
as_tibble()
# Load in second dataset in case environment clean on knit (above sections not executed for render):
results_work_rvest<- read.csv("Data extraction/work_titles.csv") %>%
as_tibble()
# Merge our two datasets:
results_work2 <- results_work %>%
as_tibble() %>%
rename("Title_trunc" = "Title") %>% # Designate the truncated title from our primary dataset so we can remove it once we get the full title
full_join(results_work_rvest, by = "PMID") %>%
select(-Title_trunc) %>% # Bye truncated title
relocate(Title) %>% # Place full title first for ease
print()
# Total number with basic duplication removal based on title:
Simple_duplicate_removal_n <- results_work2 %>%
distinct(Title) %>%
count() %>%
print() # None
# Total number with basic duplication removal based on title:
Simple_duplicate_removal_n <- results_work2 %>%
distinct(PMID) %>%
count() %>%
print() # None
# Have a look at duplicates where the title, year, and authors are all the same:
results_work2 %>%
group_by(Title,
Journal_name_short,
Full_Author_Name) %>%
filter(n()>1)
print() # None
# Load in first dataset in case environment clean on knit (above sections not executed for render):
results_work<- read.csv("Data extraction/work_data.csv") %>%
as_tibble()
# Load in second dataset in case environment clean on knit (above sections not executed for render):
results_work_rvest<- read.csv("Data extraction/work_titles.csv") %>%
as_tibble()
# Merge our two datasets:
results_work2 <- results_work %>%
as_tibble() %>%
rename("Title_trunc" = "Title") %>% # Designate the truncated title from our primary dataset so we can remove it once we get the full title
full_join(results_work_rvest, by = "PMID") %>%
select(-Title_trunc) %>% # Bye truncated title
relocate(Title) %>% # Place full title first for ease
print()
# Total number with basic duplication removal based on title:
Simple_duplicate_removal_n <- results_work2 %>%
distinct(Title) %>%
count() %>%
print() # None
# Total number with basic duplication removal based on title:
Simple_duplicate_removal_n <- results_work2 %>%
distinct(PMID) %>%
count() %>%
print() # None
# Have a look at duplicates where the title, year, and authors are all the same:
results_work2 %>%
group_by(Title,
Journal_name_short,
Full_Author_Name) %>%
filter(n()>1)
print() # None
# Have a look at duplicates where the title, year, and authors are all the same:
results_work2 %>%
group_by(Title,
Journal_name_short,
Full_Author_Name) %>%
filter(n()>1) # None
# Have a look at duplicates were just the title, journal and year are the same:
results_work2 %>%
group_by(Title,
Journal_name_short,
Year) %>%
filter(n()>1) %>%
print() # None
results_work2_relevent <- results_work2 %>%
filter(Title != "Overearning.") # There is a. At the end of the total in the extracted data for some reason
# Summary of the Year  variable:
summary(results_work2_relevent$Year)
# Number of publications per year:
work_hist<- hist(results_work2_relevent$Year,
xlim = c(1960,2023),
breaks = 40,
main = "Papers published per year on Work Addiction (PubMed)",
xlab = "Year")
# Number of separate journals:
results_work2_relevent %>%
distinct(Journal_name_short) %>%
arrange(Journal_name_short) %>%
print(n = 20)
# Most popular journals:
results_work2_relevent %>%
group_by(Journal_name_short) %>%
summarise(
n = n()
) %>%
arrange(desc(n)) %>%
print(n = 20)
Label_work <- rep("work", times = count(results_work2_relevent))
results_work_final <- results_work2_relevent %>%
bind_cols(Label_work) %>%
rename(Label = 14) %>%
print()
# View(results_work_final)
# Now save the cleaned results
write.csv(results_work_final, "Data extraction/work_data_cleaned.csv", row.names=FALSE)
# Load in first dataset in case environment clean on knit (above sections not executed for render):
results_exercise<- read.csv("Data extraction/exercise_data.csv") %>%
as_tibble()
# Load in second dataset in case environment clean on knit (above sections not executed for render):
results_exercise_rvest<- read.csv("Data extraction/exercise_titles.csv") %>%
as_tibble()
# Merge our two datasets
results_exercise2 <- results_exercise %>%
as_tibble() %>%
rename("Title_trunc" = "Title") %>% # Designate the truncated title from our primary dataset so we can remove it once we get the full title
full_join(results_exercise_rvest, by = "PMID") %>%
select(-Title_trunc) %>% # Bye truncated title
relocate(Title) %>% # Place full title first for ease
print()
# Check results:
# View(results_exercise2)
# Total number with basic duplication removal based on title:
Simple_duplicate_removal_n <- results_exercise2 %>%
distinct(Title) %>%
count() %>%
print() # n = 2 dupes (jUly 2023)
# Show duplicate:
results_exercise2 %>%
group_by(Title) %>%
filter(n()>1) %>%
# View()
print() # These all have different PMIDs, DOIs, authors, and years
# Have a look at duplicates where the title, year, and authors are all the same:
results_exercise2 %>%
group_by(Title,
Journal_name_short,
Full_Author_Name) %>%
filter(n()>1)
# print() #None
# Have a look at duplicates were just the title, journal and year are the same:
results_exercise2 %>%
group_by(Title,
Journal_name_short,
Year) %>%
filter(n()>1) %>%
print() # None
#  Okay, now we're confident we have a clean dataset, let's explore!
# Summary of the Year  variable:
summary(results_exercise2$Year)
# Number of publications per year:
exercise_hist<- hist(results_exercise2$Year,
xlim = c(1960,2023),
breaks = 40,
main = "Papers published per year on exercise Disorder (PubMed)",
xlab = "Year")
# Number of separate journals:
results_exercise2 %>%
distinct(Journal_name_short) %>%
arrange(Journal_name_short) %>%
print(n = 20)
# Most popular journals:
results_exercise2 %>%
group_by(Journal_name_short) %>%
summarise(
n = n()
) %>%
arrange(desc(n)) %>%
print(n = 20)
# View(results_exercise2) # Visually inspect results
# Now I need to add a label to all of these studies to signify that they Were returned from the exercise search so that we can distinguish them from other studies when we later joined the datasets together:
Label <- rep("exercise", times = count(results_exercise2))
results_exercise_final <- results_exercise2 %>% bind_cols(Label) %>%
rename(Label = 14) %>%
print()
# View(results_exercise_final)
# Now save the cleaned results
write.csv(results_exercise_final, "Data extraction/exercise_data_cleaned.csv", row.names=FALSE)
# Load in first dataset in case environment clean on knit (above sections not executed for render):
results_gambling<- read.csv("Data extraction/gambling_data.csv") %>%
as_tibble()
# Load in second dataset in case environment clean on knit (above sections not executed for render):
results_gambling_rvest<- read.csv("Data extraction/gambling_titles.csv") %>%
as_tibble()
# Merge the two datasets:
results_gambling2 <- results_gambling %>%
rename("Title_trunc" = "Title") %>% # Designate the truncated title from the primary dataset
merge(results_gambling_rvest, by = "PMID") %>%
relocate(Title) %>% # Place full title first for ease
as_tibble() %>%
print()
# Check results:
# View(results_gambling2)
# Check dupliactes based on PMIDs:
Simple_duplicate_removal_n <- results_gambling2 %>%
distinct(PMID) %>%
count() %>%
print()
results_gambling2 %>%
group_by(PMID) %>%
filter(n()>1) %>%
print(n = 100)
# Remove these asap as they're clear duplicates:
results_gambling_sans_duplicates<- results_gambling2 %>%
distinct(PMID, .keep_all = TRUE) %>%
print()
# Total number with basic duplication removal based on title (there are some distinct papers with the same title like "gambling disorder", so this is too simplified, but it'll do for a quick check):
Simple_duplicate_removal_n <- results_gambling2 %>%
distinct(Title) %>%
count() %>%
print()
# How many duplicates (based on title alone) does this remove?
count(results_gambling_sans_duplicates) - Simple_duplicate_removal_n
# Have a look at duplicates where the title, year, and authors are all the same:
results_gambling_sans_duplicates %>%
group_by(Title, Journal_name_short, Full_Author_Name) %>%
filter(n()>1) %>%
print()
# Have a look at duplicates were just the title, journal and year are the same:
results_gambling_sans_duplicates %>%
group_by(Title, Journal_name_short, Year) %>%
filter(n()>1) %>%
# View()
print()
# There are a few more of these, suggesting there are some papers with the same title, journal and date but different authors.
# The only one of concern is this one (PMID: 31346181) which is  agraphical abstract for another paper by the looks.
# Remove duplicates based on above observation:
results_gambling_sans_duplicates2<- results_gambling_sans_duplicates %>%
filter(PMID != "31346181") %>%
print()
# Check this has removed the duplicate:
count(results_gambling_sans_duplicates) - count(results_gambling_sans_duplicates2)
#  Okay, now we have a clean dataset, let's explore!
# Summary of the Year  variable:
summary(results_gambling_sans_duplicates2$Year)
# Number of publications per year:
Gambling_hist<- hist(results_gambling_sans_duplicates2$Year,
xlim = c(1960,2023),
breaks = 60,
main = "Papers published per year on Gambling Disorder (PubMed)",
xlab = "Year")
# Number of separate journals:
results_gambling_sans_duplicates2 %>%
distinct(Journal_name_short) %>%
arrange(Journal_name_short) %>%
print(n = 50)
# Most popular journals:
results_gambling_sans_duplicates2 %>%
group_by(Journal_name_short) %>%
summarise(
n = n()
) %>%
arrange(desc(n)) %>%
print(n = 50)
# View(results_gambling_sans_duplicates) # Visually inspect results
# Now I need to add a label to all of these studies to signify that they Were returned from the gambling search so that we can distinguish them from other studies when we later joined the datasets together:
count(results_gambling_sans_duplicates2)
Label <- rep("gambling", times = count(results_gambling_sans_duplicates2))
results_gambling_final <- results_gambling_sans_duplicates2 %>% bind_cols(Label) %>%
rename(Label = 14) %>%
print()
# View(results_gambling_final)
# Now save the cleaned results
write.csv(results_gambling_final, "Data extraction/gambling_data_cleaned.csv", row.names=FALSE)
read.csv("Data extraction/gambling_data_cleaned.csv")
# Load in first dataset in case environment clean on knit (above sections not executed for render):
results_gaming<- read.csv("Data extraction/gaming_data.csv") %>%
as_tibble()
# Load in second dataset in case environment clean on knit (above sections not executed for render):
results_gaming_rvest<- read.csv("Data extraction/gaming_titles.csv") %>%
as_tibble()
# Merge our two datasets:
results_gaming2 <- results_gaming %>%
as_tibble() %>%
rename("Title_trunc" = "Title") %>% # Designate the truncated title from our primary dataset so we can remove it once we get the full title
full_join(results_gaming_rvest, by = "PMID") %>%
select(-Title_trunc) %>% # Bye truncated title
relocate(Title) %>% # Place full title first for ease
print()
# Check results:
# View(results_gaming2)
# Total number with basic duplication removal based on title:
Simple_duplicate_removal_n <- results_gaming2 %>%
distinct(Title) %>%
count() %>%
print()
# Show duplicate:
results_gaming2 %>%
group_by(Title) %>%
filter(n()>1) # **This is actually two seperate studies**
# I know from manual searching that there is a genuine duplicate that is a corrigendum to one study. The PMID  for the corrigendum is 35543161 (Remove later)
# Have a look at duplicates where the title, year, and authors are all the same:
results_gaming2 %>%
group_by(Title,
Journal_name_short,
Full_Author_Name) %>%
filter(n()>1)
# Have a look at duplicates were just the title, journal and year are the same:
results_gaming2 %>%
group_by(Title,
Journal_name_short,
Year) %>%
filter(n()>1)
# Remove the duplicate study:
results_gaming_sans_duplicates<- results_gaming2 %>%
filter(PMID != "35543161") %>%
print()
# Check this has just remove one study
count(results_gaming2) - count(results_gaming_sans_duplicates) # Yep
#  Okay, now we have a clean dataset, let's explore!
# Summary of the Year  variable:
summary(results_gaming_sans_duplicates$Year)
# Number of publications per year:
gaming_hist<- hist(results_gaming_sans_duplicates$Year,
xlim = c(1960,2023),
breaks = 40,
main = "Papers published per year on Gaming Disorder (PubMed)",
xlab = "Year")
# Number of separate journals:
results_gaming_sans_duplicates %>%
distinct(Journal_name_short) %>%
arrange(Journal_name_short) %>%
print(n = 20)
# Most popular journals:
results_gaming_sans_duplicates %>%
group_by(Journal_name_short) %>%
summarise(
n = n()
) %>%
arrange(desc(n)) %>%
print(n = 20)
# View(results_gaming_sans_duplicates) # Visually inspect results
# Now I need to add a label to all of these studies to signify that they Were returned from the gaming search so that we can distinguish them from other studies when we later joined the datasets together:
count(results_gaming_sans_duplicates)
Label <- rep("gaming", times = count(results_gaming_sans_duplicates))
results_gaming_final <- results_gaming_sans_duplicates %>% bind_cols(Label) %>%
rename(Label = 14) %>%
print()
# View(results_gaming_final)
# Now save the cleaned results:
write.csv(results_gaming_final, "Data extraction/gaming_data_cleaned.csv", row.names=FALSE)
# Merge our two datasets:
results_gaming2 <- results_gaming %>%
as_tibble() %>%
rename("Title_trunc" = "Title") %>% # Designate the truncated title from our primary dataset so we can remove it once we get the full title
full_join(results_gaming_rvest, by = "PMID") %>%
select(-Title_trunc) %>% # Bye truncated title
relocate(Title) %>% # Place full title first for ease
print()
# Total number with basic duplication removal based on title:
Simple_duplicate_removal_n <- results_gaming2 %>%
distinct(Title) %>%
count() %>%
print()
# Show duplicate:
results_gaming2 %>%
group_by(Title) %>%
filter(n()>1) # **This is actually two seperate studies**
# Have a look at duplicates where the title, year, and authors are all the same:
results_gaming2 %>%
group_by(Title,
Journal_name_short,
Full_Author_Name) %>%
filter(n()>1)
# Have a look at duplicates were just the title, journal and year are the same:
results_gaming2 %>%
group_by(Title,
Journal_name_short,
Year) %>%
filter(n()>1)
# Remove the duplicate study:
results_gaming_sans_duplicates<- results_gaming2 %>%
filter(PMID != "35543161") %>%
print()
# Check this has just remove one study
count(results_gaming2) - count(results_gaming_sans_duplicates) # Yep
# Summary of the Year  variable:
summary(results_gaming_sans_duplicates$Year)
# Number of publications per year:
gaming_hist<- hist(results_gaming_sans_duplicates$Year,
xlim = c(1960,2023),
breaks = 40,
main = "Papers published per year on Gaming Disorder (PubMed)",
xlab = "Year")
# Number of separate journals:
results_gaming_sans_duplicates %>%
distinct(Journal_name_short) %>%
arrange(Journal_name_short) %>%
print(n = 20)
# Most popular journals:
results_gaming_sans_duplicates %>%
group_by(Journal_name_short) %>%
summarise(
n = n()
) %>%
arrange(desc(n)) %>%
print(n = 20)
# Now I need to add a label to all of these studies to signify that they Were returned from the gaming search so that we can distinguish them from other studies when we later joined the datasets together:
count(results_gaming_sans_duplicates)
Label <- rep("gaming", times = count(results_gaming_sans_duplicates))
results_gaming_final <- results_gaming_sans_duplicates %>% bind_cols(Label) %>%
rename(Label = 14) %>%
print()
# View(results_gaming_final)
# Now save the cleaned results:
write.csv(results_gaming_final, "Data extraction/gaming_data_cleaned.csv", row.names=FALSE)
# View(results_gaming_final)
# Now save the cleaned results:
write.csv(results_gaming_final, "Data extraction/gaming_data_cleaned.csv", row.names=FALSE)
