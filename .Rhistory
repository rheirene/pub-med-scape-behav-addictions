print()
# Let#s check in many decodes we get when we do this:
results_gambling2 %>%
group_by(Title, Full_Author_Name) %>%
filter(n()>1) %>%
print()
results_gambling_sans_duplicates<- results_gambling2 %>%
distinct(PMID) %>%
print()
results_gambling_sans_duplicates<- results_gambling2 %>%
distinct(PMID, keep.all = TRUE) %>%
print()
results_gambling_sans_duplicates<- results_gambling2 %>%
distinct(PMID, .keep.all = TRUE) %>%
print()
results_gambling_sans_duplicates<- results_gambling2 %>%
distinct(PMID, .keep_all = TRUE) %>%
print()
# Total number with basic duplication removal based on title (there are some distinct papers with the same title like "gambling disorder", so this is too simplified, but it'll do for a quick check):
Simple_duplicate_removal_n <- results_gambling2 %>%
distinct(Title) %>%
count() %>%
print()
# How many duplicates (based on title alone) does this remove?
count(results_gambling2) - Simple_duplicate_removal_n
# Have a look at duplicates where the title, year, and authors are all the same:
results_gambling2 %>%
group_by(Title, Journal_name_short, Full_Author_Name) %>%
filter(n()>1) %>%
print()
# Have a look at duplicates where the title, year, and authors are all the same:
results_gambling_sans_duplicates %>%
group_by(Title, Journal_name_short, Full_Author_Name) %>%
filter(n()>1) %>%
print()
# Have a look at duplicates were just the title, journal and year are the same:
results_gambling_sans_duplicates %>%
group_by(Title, Journal_name_short, Year) %>%
filter(n()>1) %>%
print()
# Merge our two datasets
results_gambling2 <- results_gambling %>%
rename("Title_trunc" = "Title") %>% # Designate the truncated title from our primary dataset
left_join(results_gambling_rvest, by = "PMID") %>%
relocate(Title) %>% # Place full title first for ease
print()
# Check results:
View(results_gambling2)
# Check dupliactes based on PMIDs:
Simple_duplicate_removal_n <- results_gambling2 %>%
distinct(PMID) %>%
count() %>%
print()
# Remove these asap as there's no debate about them being dupliactes or not:
results_gambling_sans_duplicates<- results_gambling2 %>%
distinct(PMID, .keep_all = TRUE) %>%
print()
# Total number with basic duplication removal based on title (there are some distinct papers with the same title like "gambling disorder", so this is too simplified, but it'll do for a quick check):
Simple_duplicate_removal_n <- results_gambling2 %>%
distinct(Title) %>%
count() %>%
print()
# How many duplicates (based on title alone) does this remove?
count(results_gambling2) - Simple_duplicate_removal_n
# Have a look at duplicates where the title, year, and authors are all the same:
results_gambling_sans_duplicates %>%
group_by(Title, Journal_name_short, Full_Author_Name) %>%
filter(n()>1) %>%
print()
# Have a look at duplicates were just the title, journal and year are the same:
results_gambling_sans_duplicates %>%
group_by(Title, Journal_name_short, Year) %>%
filter(n()>1) %>%
print()
# Let#s check in many duplicates we get when we do this:
results_gambling2 %>%
group_by(Title, Full_Author_Name) %>%
filter(n()>1) %>%
print()
# Let#s check in many duplicates we get when we do this:
results_gambling_sans_duplicates %>%
group_by(Title, Full_Author_Name) %>%
filter(n()>1) %>%
print()
results_gambling_rvest
results_gambling2
is.na(results_gambling2$Title)
# Merge our two datasets
results_gambling2 <- results_gambling %>%
rename("Title_trunc" = "Title") %>% # Designate the truncated title from our primary dataset
full_join(results_gambling_rvest, by = "PMID") %>%
relocate(Title) %>% # Place full title first for ease
print()
is.na(results_gambling2$Title)
# Merge our two datasets
results_gambling2 <- results_gambling %>%
rename("Title_trunc" = "Title") %>% # Designate the truncated title from our primary dataset
merge(results_gambling_rvest, by = "PMID") %>%
relocate(Title) %>% # Place full title first for ease
print()
results_gambling2
# Check results:
View(results_gambling2)
is.na(results_gambling2$Title)
results_gambling2
# Merge our two datasets
results_gambling2 <- results_gambling %>%
rename("Title_trunc" = "Title") %>% # Designate the truncated title from our primary dataset
merge(results_gambling_rvest, by = "PMID") %>%
relocate(Title) %>% # Place full title first for ease
as_tibble() %>%
print()
# Check dupliactes based on PMIDs:
Simple_duplicate_removal_n <- results_gambling2 %>%
distinct(PMID) %>%
count() %>%
print()
# Remove these asap as there's no debate about them being dupliactes or not:
results_gambling_sans_duplicates<- results_gambling2 %>%
distinct(PMID, .keep_all = TRUE) %>%
print()
# Check dupliactes based on PMIDs:
Simple_duplicate_removal_n <- results_gambling2 %>%
distinct(PMID) %>%
count() %>%
print()
# Remove these asap as there's no debate about them being dupliactes or not:
results_gambling_sans_duplicates<- results_gambling2 %>%
distinct(PMID, .keep_all = TRUE) %>%
print()
# Total number with basic duplication removal based on title (there are some distinct papers with the same title like "gambling disorder", so this is too simplified, but it'll do for a quick check):
Simple_duplicate_removal_n <- results_gambling2 %>%
distinct(Title) %>%
count() %>%
print()
# How many duplicates (based on title alone) does this remove?
count(results_gambling2) - Simple_duplicate_removal_n
# How many duplicates (based on title alone) does this remove?
count(results_gambling_sans_duplicates) - Simple_duplicate_removal_n
# Have a look at duplicates where the title, year, and authors are all the same:
results_gambling_sans_duplicates %>%
group_by(Title, Journal_name_short, Full_Author_Name) %>%
filter(n()>1) %>%
print()
# Have a look at duplicates were just the title, journal and year are the same:
results_gambling_sans_duplicates %>%
group_by(Title, Journal_name_short, Year) %>%
filter(n()>1) %>%
print()
# Remove these asap as there's no debate about them being dupliactes or not:
results_gambling_sans_duplicates<- results_gambling2 %>%
distinct(PMID, .keep_all = TRUE) %>%
print()
results_gambling2 %>%
group_by(PMID) %>%
filter(n()>1) %>%
print()
results_gambling2 %>%
group_by(PMID) %>%
filter(n()>1) %>%
print(n = 100)
# Have a look at duplicates were just the title, journal and year are the same:
results_gambling_sans_duplicates %>%
group_by(Title, Journal_name_short, Year) %>%
filter(n()>1) %>%
print()
# Have a look at duplicates were just the title, journal and year are the same:
results_gambling_sans_duplicates %>%
group_by(Title, Journal_name_short, Year) %>%
filter(n()>1) %>%
View()
# Let#s check in many duplicates we get when we do this:
results_gambling_sans_duplicates %>%
group_by(Title, Full_Author_Name) %>%
filter(n()>1) %>%
print()
# Have a look at duplicates were just the title, journal and year are the same:
results_gambling_sans_duplicates %>%
group_by(Title, Journal_name_short, Year) %>%
filter(n()>1) %>%
View()
# Remove duplicates based on only duplicated titles and authors:
results_gambling_sans_duplicates2<- results_gambling2 %>%
filter(PubMed_ID != "31346181") %>%
print()
# Remove duplicates based on only duplicated titles and authors:
results_gambling_sans_duplicates2<- results_gambling2 %>%
filter(PMID != "31346181") %>%
print()
# This has removed the duplicates:
results_gambling_sans_duplicates %>%
group_by(Title, Full_Author_Name) %>%
filter(n()>1) %>% print()
# This has removed the duplicates:
results_gambling_sans_duplicates2 %>%
group_by(Title, Full_Author_Name) %>%
filter(n()>1) %>% print()
# Remove duplicates based on only duplicated titles and authors:
results_gambling_sans_duplicates2<- results_gambling2 %>%
filter(PMID != "31346181") %>%
print()
# Remove duplicates based on only duplicated titles and authors:
results_gambling_sans_duplicates2<- results_gambling_sans_duplicates %>%
filter(PMID != "31346181") %>%
print()
# This has removed the duplicates:
results_gambling_sans_duplicates2 %>%
group_by(Title, Full_Author_Name) %>%
filter(n()>1) %>% print()
# This has removed the duplicates:
count(results_gambling_sans_duplicates) - count(results_gambling_sans_duplicates2)
# Number of publications per year:
Gambling_hist<- hist(results_gambling_sans_duplicates2$Year,
xlim = c(1960,2023),
breaks = 60,
main = "Papers published per year on Gambling Disorder (PubMed)",
xlab = "Year")
# Summary of the Year  variable:
summary(results_gambling_sans_duplicates2$Year)
# Number of publications per year:
Gambling_hist<- hist(results_gambling_sans_duplicates2$Year,
xlim = c(1960,2023),
breaks = 60,
main = "Papers published per year on Gambling Disorder (PubMed)",
xlab = "Year")
# Number of separate journals:
results_gambling_sans_duplicates %>%
distinct(Journal_name_short) %>%
arrange(Journal_name_short) %>%
print(n = 50)
# Number of separate journals:
results_gambling_sans_duplicates2 %>%
distinct(Journal_name_short) %>%
arrange(Journal_name_short) %>%
print(n = 50)
# Most popular journals:
results_gambling_sans_duplicates2 %>%
group_by(Journal_name_short) %>%
summarise(
n = n()
) %>%
arrange(desc(n)) %>%
print(n = 50)
# Now I need to add a label to all of these studies to signify that they Were returned from the gambling search so that we can distinguish them from other studies when we later joined the datasets together:
count(results_gambling_sans_duplicates2)
Label <- rep("gambling", times = count(results_gambling_sans_duplicates2))
results_gambling_final <- results_gambling_sans_duplicates2 %>% bind_cols(Label) %>%
rename(Label = 14) %>%
print()
View(results_gambling_final)
# Number of publications per year:
Gambling_hist<- hist(results_gambling_sans_duplicates2$Year,
xlim = c(1960,2023),
breaks = 60,
main = "Papers published per year on Gambling Disorder (PubMed)",
xlab = "Year")
# Number of separate journals:
results_gambling_sans_duplicates2 %>%
distinct(Journal_name_short) %>%
arrange(Journal_name_short) %>%
print(n = 50)
# Most popular journals:
results_gambling_sans_duplicates2 %>%
group_by(Journal_name_short) %>%
summarise(
n = n()
) %>%
arrange(desc(n)) %>%
print(n = 50)
# Now I need to add a label to all of these studies to signify that they Were returned from the gambling search so that we can distinguish them from other studies when we later joined the datasets together:
count(results_gambling_sans_duplicates2)
Label <- rep("gambling", times = count(results_gambling_sans_duplicates2))
results_gambling_final <- results_gambling_sans_duplicates2 %>% bind_cols(Label) %>%
rename(Label = 14) %>%
print()
write.csv(results_gambling_final, "C:/Users/rheirene/Dropbox (Personal)/Sci-Software/Blog posts/PubMed Article Scraping/Web scrape scholar/Data extraction/gambling_data_cleaned.csv", row.names=FALSE)
# Load required libraries:
library(rentrez)
library(dplyr)
library(purrr)
library(rvest)
#  Clean environment:
rm(list = ls())
# Define the search term:
search_term_gambling <- '("gambling"[Title/Abstract])'
# Use entrez_search to get the IDs of the articles:
search_results_gambling <- entrez_search(db="pubmed", term=search_term_gambling, retmax=20000)
id_list_gambling <- search_results_gambling$ids
# Split id list into chunks of 500:
chunks <- split(id_list_gambling, ceiling(seq_along(id_list_gambling)/100))
# Fetch details for each chunk of articles:
article_details_gambling <- map_dfr(chunks, function(ids) {
# Fetch details of the articles:
articles <- entrez_fetch(db="pubmed", id=ids, rettype="medline", retmode="text")
# Split the articles into individual articles:
articles <- strsplit(articles, "\n\n")[[1]]
# Process each article:
map_dfr(articles, function(article) {
# Split the article into lines:
lines <- strsplit(article, "\n")[[1]]
# Get the details we're interested in:
details_gambling <- list(
PMID = if (any(grepl("^PMID", lines))) lines[grepl("^PMID", lines)] else NA,
DP = if (any(grepl("^DP", lines))) lines[grepl("^DP", lines)] else NA,
TI = if (any(grepl("^TI", lines))) lines[grepl("^TI", lines)] else NA,
LID = if (any(grepl("^LID", lines))) paste(lines[grepl("^LID", lines)], collapse="; ") else NA,
AB = if (any(grepl("^AB", lines))) paste(lines[grepl("^AB", lines)], collapse=" ") else NA,
FAU = if (any(grepl("^FAU", lines))) paste(lines[grepl("^FAU", lines)], collapse="; ") else NA,
AD = if (any(grepl("^AD", lines))) paste(lines[grepl("^AD", lines)], collapse="; ") else NA,
LA = if (any(grepl("^LA", lines))) paste(lines[grepl("^LA", lines)], collapse="; ") else NA,
PT = if (any(grepl("^PT", lines))) paste(lines[grepl("^PT", lines)], collapse="; ") else NA,
TA = if (any(grepl("^TA", lines))) lines[grepl("^TA", lines)] else NA,
COIS = if (any(grepl("^COIS", lines))) paste(lines[grepl("^COIS", lines)], collapse=" ") else NA,
JT = if (any(grepl("^JT", lines))) lines[grepl("^JT", lines)] else NA
)
# Convert the list of details into a one-row data frame:
details_df_gambling <- bind_rows(details_gambling)
return(details_df_gambling)
})
})
# Check the results:
article_details_gambling %>%
as_tibble() %>%
print()
# Let's remove the identifiers at the beginning of each data point:
rep_str <- c('PMID- ' = '', 'DP  - ' = '', 'TI  - ' = '', 'LID - ' = '', 'AB  - ' = '',
'FAU - ' = '', 'AD  - ' = '', 'LA  - ' = '', 'PT  - ' = '', 'TA  - ' = '',
'COIS- ' = '', 'JT  - ' = '')
results_gambling <- article_details_gambling %>%
mutate(across(everything(), ~str_replace_all(., rep_str))) %>% # Remove identifiers
# Now separate the date year and month/day info:
separate(DP, c("Year", "Month"), sep = "\\ ") %>%
mutate(Year = as.numeric(Year)) %>% # Convert Year to numeric
rename( # Let's also provide more descriptive names for each of the columns
"Title" = "TI",
"DOI" = "LID",
"Abstract" = "AB",
"Full_Author_Name" = "FAU",
"Author_Address" = "AD",
"Language" = "LA",
"Publication_Type" = "PT",
"Journal_name_short" = "TA",
"Conflict_of_Interest_Statement" = "COIS",
"Journal_Title" = "JT") %>%
print()
library(tidyr)
results_gambling <- article_details_gambling %>%
mutate(across(everything(), ~str_replace_all(., rep_str))) %>% # Remove identifiers
# Now separate the date year and month/day info:
separate(DP, c("Year", "Month"), sep = "\\ ") %>%
mutate(Year = as.numeric(Year)) %>% # Convert Year to numeric
rename( # Let's also provide more descriptive names for each of the columns
"Title" = "TI",
"DOI" = "LID",
"Abstract" = "AB",
"Full_Author_Name" = "FAU",
"Author_Address" = "AD",
"Language" = "LA",
"Publication_Type" = "PT",
"Journal_name_short" = "TA",
"Conflict_of_Interest_Statement" = "COIS",
"Journal_Title" = "JT") %>%
print()
library(stringr)
results_gambling <- article_details_gambling %>%
mutate(across(everything(), ~str_replace_all(., rep_str))) %>% # Remove identifiers
# Now separate the date year and month/day info:
separate(DP, c("Year", "Month"), sep = "\\ ") %>%
mutate(Year = as.numeric(Year)) %>% # Convert Year to numeric
rename( # Let's also provide more descriptive names for each of the columns
"Title" = "TI",
"DOI" = "LID",
"Abstract" = "AB",
"Full_Author_Name" = "FAU",
"Author_Address" = "AD",
"Language" = "LA",
"Publication_Type" = "PT",
"Journal_name_short" = "TA",
"Conflict_of_Interest_Statement" = "COIS",
"Journal_Title" = "JT") %>%
print()
# Now save the initial results before proceeding so we can't lose them!
write.csv(results_gambling, "ALL_gambling_data.csv", row.names=FALSE)
results_gambling %>%
group_by(Year) %>%
count()
results_gambling %>%
group_by(Year) %>%
count() %>%
view()
results_gambling %>%
group_by(Year) %>%
count() %>%
view()
results_gambling %>%
group_by(Year) %>%
count() %>%
View()
results_gambling %>%
group_by(Year) %>%
count() %>%
write.csv("ALL_gambling_data_BY_YEAR_N.csv", row.names=FALSE)
results_gambling %>%
group_by(Year) %>%
count() %>%
sum()
results_gambling %>%
group_by(Year) %>%
sum()
results_gambling %>%
group_by(Year) %>%
sum(n)
results_gambling %>%
group_by(Year) %>%
sum(Year)
results_gambling
results_gambling %>%
n()
results_gambling %>%
count()
results_gambling %>%
group_by(Year) %>%
flter(Year < 2011) %>%
count()
results_gambling %>%
group_by(Year) %>%
filter(Year < 2011) %>%
count()
results_gambling %>%
group_by(Year) %>%
filter(Year < 2011) %>%
summarise(
n = sum(n)
)
results_gambling %>%
group_by(Year) %>%
filter(Year < 2011) %>%
summarise(
sum(n)
)
results_gambling %>%
group_by(Year) %>%
filter(Year < 2011) %>%
summarize(
sum(n)
)
results_gambling %>%
group_by(Year) %>%
filter(Year < 2011)
results_gambling %>%
group_by(Year) %>%
filter(Year < 2011) %>%
sum(n)
results_gambling %>%
group_by(Year) %>%
filter(Year < 2011)
results_gambling %>%
group_by(Year) %>%
count() %>%
filter(Year < 2011) %>%
sum(n)
results_gambling %>%
group_by(Year) %>%
count() %>%
filter(Year < 2011)
results_gambling %>%
group_by(Year) %>%
count() %>%
filter(Year < 2011) %>%
summarize(total= sum(n))
results_gambling %>%
group_by(Year) %>%
count() %>%
filter(Year < 2011) %>%
summarize(total= sum(n))
results_gambling %>%
group_by(Year) %>%
count() %>%
filter(Year < 2011) %>%
ungroup() %>%
summarize(total= sum(n))
results_gambling %>%
group_by(Year) %>%
count() %>%
filter(Year => 2011) %>%
results_gambling %>%
group_by(Year) %>%
count() %>%
filter(Year => 2011) %>%
results_gambling %>%
group_by(Year) %>%
count() %>%
filter(Year >= 2011) %>%
ungroup() %>%
summarize(total= sum(n)) #
results_gambling %>%
count()
2731/count(results_gambling)*100
results_gambling %>%
group_by(Year) %>%
count() %>%
filter(Year < 2013) %>%
ungroup() %>%
summarize(total= sum(n)) # 2731
results_gambling %>%
group_by(Year) %>%
count() %>%
filter(Year >= 2013) %>%
ungroup() %>%
summarize(total= sum(n)) # 6684
3496/count(results_gambling)*100
5919/count(results_gambling)*100
